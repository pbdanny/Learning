{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Basic Deep Learning","metadata":{}},{"cell_type":"markdown","source":"## Forward Propagation","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-08-07T02:11:07.949515Z","iopub.execute_input":"2021-08-07T02:11:07.949858Z","iopub.status.idle":"2021-08-07T02:11:07.953844Z","shell.execute_reply.started":"2021-08-07T02:11:07.949823Z","shell.execute_reply":"2021-08-07T02:11:07.952891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image('https://s3.amazonaws.com/assets.datacamp.com/production/course_3524/datasets/1_4.png')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T02:11:23.31385Z","iopub.execute_input":"2021-08-07T02:11:23.314309Z","iopub.status.idle":"2021-08-07T02:11:24.514857Z","shell.execute_reply.started":"2021-08-07T02:11:23.314277Z","shell.execute_reply":"2021-08-07T02:11:24.514168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_data = np.array([3,5])\nweights = {'node_0': np.array([2, 4]), 'node_1': np.array([ 4, -5]), 'output': np.array([2, 7])}","metadata":{"execution":{"iopub.status.busy":"2021-08-07T02:26:02.180617Z","iopub.execute_input":"2021-08-07T02:26:02.180991Z","iopub.status.idle":"2021-08-07T02:26:02.185991Z","shell.execute_reply.started":"2021-08-07T02:26:02.180956Z","shell.execute_reply":"2021-08-07T02:26:02.184794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imitage dot products with element-wise multiplication & sum\nnode_0_value = (input_data * weights['node_0']).sum() # matrix form input_data@weights['node_0']\nnode_1_value = (input_data * weights['node_1']).sum() # matrix form input_data@weights['node_1']","metadata":{"execution":{"iopub.status.busy":"2021-08-07T02:27:15.368244Z","iopub.execute_input":"2021-08-07T02:27:15.368611Z","iopub.status.idle":"2021-08-07T02:27:15.372457Z","shell.execute_reply.started":"2021-08-07T02:27:15.368581Z","shell.execute_reply":"2021-08-07T02:27:15.371617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hidden_layer_outputs = np.array([node_0_value, node_1_value])\noutput = (hidden_layer_outputs * weights['output']).sum()\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T02:27:16.049349Z","iopub.execute_input":"2021-08-07T02:27:16.04983Z","iopub.status.idle":"2021-08-07T02:27:16.054707Z","shell.execute_reply.started":"2021-08-07T02:27:16.049799Z","shell.execute_reply":"2021-08-07T02:27:16.053893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Activation Fn  \ncapture Linear / Non-linear relationship in each node  \n`ReLu (Rectify Linear activation)` is the most efficient & used","metadata":{}},{"cell_type":"code","source":"def relu(input):\n    return max(input, 0)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:59:56.364357Z","iopub.execute_input":"2021-08-07T04:59:56.364954Z","iopub.status.idle":"2021-08-07T04:59:56.368731Z","shell.execute_reply.started":"2021-08-07T04:59:56.364919Z","shell.execute_reply":"2021-08-07T04:59:56.367859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = np.array([3, 2])\nweights = {'node_0':np.array([2,1]), 'node_1':np.array([0, 0]), 'output':np.array([2,2])}\n\nnode_0_value = (inputs * weights['node_0']).sum()\nnode_0_output = relu(node_0_value)\n\nnode_1_value = (inputs * weights['node_1']).sum() \nnode_1_output = relu(node_1_value)\n\nhidden_layer_data = np.array([node_0_output, node_1_output])\n\nhidden_layer_value = (hidden_layer_data * weights['output']).sum()\n# hidden_layer_output = relu(hidden_layer_value)\nhidden_layer_output = hidden_layer_value\n\nprint(hidden_layer_output)\nprint(hidden_layer_output-5)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:31:45.290123Z","iopub.execute_input":"2021-08-07T03:31:45.290647Z","iopub.status.idle":"2021-08-07T03:31:45.298872Z","shell.execute_reply.started":"2021-08-07T03:31:45.290599Z","shell.execute_reply":"2021-08-07T03:31:45.297854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optimization the error","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:59:07.347826Z","iopub.execute_input":"2021-08-07T04:59:07.348508Z","iopub.status.idle":"2021-08-07T04:59:08.420827Z","shell.execute_reply.started":"2021-08-07T04:59:07.348417Z","shell.execute_reply":"2021-08-07T04:59:08.419637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = np.array([0, 3])\ntarget_actual = 3\n\nweights = {'node_0':np.array([2,1]), 'node_1':np.array([1, 2]), 'output':np.array([1,1])}\n\nnode_0_value = (inputs * weights['node_0']).sum()\nnode_0_output = relu(node_0_value)\n\nnode_1_value = (inputs * weights['node_1']).sum() \nnode_1_output = relu(node_1_value)\n\nhidden_layer_data = np.array([node_0_output, node_1_output])\n\nhidden_layer_value = (hidden_layer_data * weights['output']).sum()\n# hidden_layer_output = relu(hidden_layer_value)\nhidden_layer_output = hidden_layer_value\n\nprint(f'Target : Predict={hidden_layer_output}, Actual={target_actual}, error={hidden_layer_output-target_actual}')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:59:59.740663Z","iopub.execute_input":"2021-08-07T04:59:59.741382Z","iopub.status.idle":"2021-08-07T04:59:59.752866Z","shell.execute_reply.started":"2021-08-07T04:59:59.741333Z","shell.execute_reply":"2021-08-07T04:59:59.75181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Descend","metadata":{}},{"cell_type":"markdown","source":"## Backpropagation","metadata":{}},{"cell_type":"markdown","source":"# Keras","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nimport keras\nfrom keras.layers import Dense\nfrom keras.models import Sequential, load_model\nfrom keras.utils import to_categorical\nfrom keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:05:11.367683Z","iopub.execute_input":"2021-08-07T08:05:11.368110Z","iopub.status.idle":"2021-08-07T08:05:11.374059Z","shell.execute_reply.started":"2021-08-07T08:05:11.368075Z","shell.execute_reply":"2021-08-07T08:05:11.372591Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"df = \\\n(pd\n .read_csv('../input/titanic/train.csv')\n .drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n .rename(columns=str.lower)\n .assign(male = lambda x : pd.get_dummies(x['sex'], drop_first=True))\n .drop('sex', axis=1)\n .dropna()\n .reset_index(drop=True)\n)\n\nemb_encode = pd.get_dummies(df['embarked'], prefix='embark')\n\ndf = pd.concat([df.drop('embarked', axis=1), emb_encode], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:46:51.928620Z","iopub.execute_input":"2021-08-07T07:46:51.929240Z","iopub.status.idle":"2021-08-07T07:46:51.960081Z","shell.execute_reply.started":"2021-08-07T07:46:51.929200Z","shell.execute_reply":"2021-08-07T07:46:51.959164Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:46:52.353912Z","iopub.execute_input":"2021-08-07T07:46:52.354614Z","iopub.status.idle":"2021-08-07T07:46:52.372520Z","shell.execute_reply.started":"2021-08-07T07:46:52.354550Z","shell.execute_reply":"2021-08-07T07:46:52.371278Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"   survived  pclass   age  sibsp  parch     fare  male  embark_C  embark_Q  \\\n0         0       3  22.0      1      0   7.2500     1         0         0   \n1         1       1  38.0      1      0  71.2833     0         1         0   \n2         1       3  26.0      0      0   7.9250     0         0         0   \n3         1       1  35.0      1      0  53.1000     0         0         0   \n4         0       3  35.0      0      0   8.0500     1         0         0   \n\n   embark_S  \n0         1  \n1         0  \n2         1  \n3         1  \n4         1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>survived</th>\n      <th>pclass</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>male</th>\n      <th>embark_C</th>\n      <th>embark_Q</th>\n      <th>embark_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:46:53.353529Z","iopub.execute_input":"2021-08-07T07:46:53.354167Z","iopub.status.idle":"2021-08-07T07:46:53.366800Z","shell.execute_reply.started":"2021-08-07T07:46:53.354116Z","shell.execute_reply":"2021-08-07T07:46:53.365500Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"survived    0\npclass      0\nage         0\nsibsp       0\nparch       0\nfare        0\nmale        0\nembark_C    0\nembark_Q    0\nembark_S    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"target = to_categorical(df['survived'])\npredictors = df.drop('survived', axis=1).to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:46:53.816368Z","iopub.execute_input":"2021-08-07T07:46:53.816839Z","iopub.status.idle":"2021-08-07T07:46:53.825823Z","shell.execute_reply.started":"2021-08-07T07:46:53.816795Z","shell.execute_reply":"2021-08-07T07:46:53.824670Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"n_cols = predictors.shape[1]\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='relu', input_shape=(n_cols,)))\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(predictors, target, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:46:54.996354Z","iopub.execute_input":"2021-08-07T07:46:54.996819Z","iopub.status.idle":"2021-08-07T07:46:55.732296Z","shell.execute_reply.started":"2021-08-07T07:46:54.996780Z","shell.execute_reply":"2021-08-07T07:46:55.731177Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Epoch 1/10\n23/23 [==============================] - 0s 1ms/step - loss: 3.7080 - accuracy: 0.5574\nEpoch 2/10\n23/23 [==============================] - 0s 1ms/step - loss: 0.8236 - accuracy: 0.6342\nEpoch 3/10\n23/23 [==============================] - 0s 1ms/step - loss: 0.8945 - accuracy: 0.6849\nEpoch 4/10\n23/23 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.6686\nEpoch 5/10\n23/23 [==============================] - 0s 1ms/step - loss: 0.6457 - accuracy: 0.6697\nEpoch 6/10\n23/23 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.7205\nEpoch 7/10\n23/23 [==============================] - 0s 1ms/step - loss: 0.6186 - accuracy: 0.6732\nEpoch 8/10\n23/23 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.6990\nEpoch 9/10\n23/23 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6454\nEpoch 10/10\n23/23 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.7144\n","output_type":"stream"},{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7faedc07da50>"},"metadata":{}}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:34:37.875913Z","iopub.execute_input":"2021-08-07T07:34:37.876597Z","iopub.status.idle":"2021-08-07T07:34:37.885999Z","shell.execute_reply.started":"2021-08-07T07:34:37.876548Z","shell.execute_reply":"2021-08-07T07:34:37.884848Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_10 (Dense)             (None, 32)                320       \n_________________________________________________________________\ndense_11 (Dense)             (None, 2)                 66        \n=================================================================\nTotal params: 386\nTrainable params: 386\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('titanic_keras_sgd.h5')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:34:39.395415Z","iopub.execute_input":"2021-08-07T07:34:39.395868Z","iopub.status.idle":"2021-08-07T07:34:39.413820Z","shell.execute_reply.started":"2021-08-07T07:34:39.395828Z","shell.execute_reply":"2021-08-07T07:34:39.412240Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"model = load_model('titanic_keras_sgd.h5')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:34:39.773796Z","iopub.execute_input":"2021-08-07T07:34:39.774223Z","iopub.status.idle":"2021-08-07T07:34:39.833714Z","shell.execute_reply.started":"2021-08-07T07:34:39.774186Z","shell.execute_reply":"2021-08-07T07:34:39.832413Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"model.predict(predictors)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:34:40.344771Z","iopub.execute_input":"2021-08-07T07:34:40.345224Z","iopub.status.idle":"2021-08-07T07:34:40.450807Z","shell.execute_reply.started":"2021-08-07T07:34:40.345172Z","shell.execute_reply":"2021-08-07T07:34:40.449515Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"array([[0.85329556, 0.1467044 ],\n       [0.36334983, 0.63665015],\n       [0.8536829 , 0.14631714],\n       ...,\n       [0.45185217, 0.5481478 ],\n       [0.5074541 , 0.49254596],\n       [0.8951586 , 0.10484146]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"predict_prob_true = model.predict(predictors)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:35:27.991358Z","iopub.execute_input":"2021-08-07T07:35:27.991956Z","iopub.status.idle":"2021-08-07T07:35:28.056626Z","shell.execute_reply.started":"2021-08-07T07:35:27.991917Z","shell.execute_reply":"2021-08-07T07:35:28.055522Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"predict_prob_true","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:35:28.338620Z","iopub.execute_input":"2021-08-07T07:35:28.339043Z","iopub.status.idle":"2021-08-07T07:35:28.356479Z","shell.execute_reply.started":"2021-08-07T07:35:28.339008Z","shell.execute_reply":"2021-08-07T07:35:28.355264Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"array([0.1467044 , 0.63665015, 0.14631714, 0.57277817, 0.07680956,\n       0.36477587, 0.4363523 , 0.13846324, 0.55326533, 0.47197378,\n       0.11934554, 0.17322321, 0.22133343, 0.2852464 , 0.06151647,\n       0.4097411 , 0.19528764, 0.31806064, 0.13247266, 0.29929247,\n       0.50919527, 0.4411567 , 0.24320592, 0.8970066 , 0.2977688 ,\n       0.01863759, 0.6848079 , 0.50832367, 0.16308774, 0.41533646,\n       0.4103554 , 0.07735638, 0.3731331 , 0.5537116 , 0.24043891,\n       0.42966998, 0.46009192, 0.16057724, 0.61736846, 0.38553017,\n       0.32761577, 0.2614563 , 0.11563464, 0.49537376, 0.44050837,\n       0.16298707, 0.6440201 , 0.43392786, 0.17618144, 0.18559858,\n       0.2350274 , 0.13059966, 0.12788208, 0.4515972 , 0.65812206,\n       0.19225857, 0.58171564, 0.12751932, 0.5085093 , 0.15452075,\n       0.16358417, 0.11492053, 0.5700172 , 0.32478106, 0.16234863,\n       0.46967545, 0.90074736, 0.13758087, 0.1059069 , 0.17090024,\n       0.5390825 , 0.30374256, 0.01571602, 0.08864559, 0.6415833 ,\n       0.27771518, 0.3256318 , 0.13200055, 0.6609803 , 0.08862859,\n       0.0697846 , 0.11064816, 0.18900456, 0.06459161, 0.45981228,\n       0.44761154, 0.15418723, 0.2252992 , 0.4274906 , 0.16182856,\n       0.00644961, 0.30577344, 0.9193221 , 0.4342992 , 0.61922777,\n       0.3834481 , 0.16935515, 0.57663304, 0.4245368 , 0.13051856,\n       0.04135466, 0.09473287, 0.16208923, 0.07091132, 0.38553017,\n       0.20937777, 0.28027108, 0.49844757, 0.5501734 , 0.23766553,\n       0.69650334, 0.18008272, 0.27290237, 0.19116984, 0.29462406,\n       0.5213605 , 0.1159256 , 0.481481  , 0.2704872 , 0.08704352,\n       0.05164956, 0.6414533 , 0.02428132, 0.06802027, 0.50339144,\n       0.27880862, 0.10045981, 0.06821312, 0.13497745, 0.12195627,\n       0.21640462, 0.4503092 , 0.47161663, 0.15372163, 0.5971616 ,\n       0.12369912, 0.4235278 , 0.46210375, 0.16182856, 0.1466054 ,\n       0.17576471, 0.2012165 , 0.16195329, 0.04994255, 0.41989163,\n       0.5112131 , 0.49027058, 0.19113386, 0.09783222, 0.07208148,\n       0.1735367 , 0.31176814, 0.21013466, 0.49607232, 0.24727347,\n       0.8273665 , 0.04815367, 0.25856745, 0.12104612, 0.07405265,\n       0.04584345, 0.19578965, 0.4760234 , 0.14125524, 0.30022523,\n       0.27908832, 0.33266124, 0.12986106, 0.22673668, 0.14662042,\n       0.16195329, 0.7604402 , 0.13911504, 0.2041603 , 0.68604165,\n       0.1416    , 0.2205117 , 0.1881495 , 0.03141578, 0.68499917,\n       0.16730905, 0.24843039, 0.15958653, 0.3377926 , 0.68093926,\n       0.10426934, 0.03490776, 0.43254507, 0.19045371, 0.16404505,\n       0.51124203, 0.24843039, 0.1339703 , 0.14890845, 0.14546633,\n       0.1068799 , 0.67262655, 0.15264112, 0.25452513, 0.53014034,\n       0.09774284, 0.13279735, 0.08054987, 0.15911497, 0.11061443,\n       0.17637351, 0.70746905, 0.993771  , 0.12952305, 0.42491823,\n       0.58760124, 0.06135218, 0.10383506, 0.45721817, 0.12964827,\n       0.82264125, 0.7972963 , 0.09293445, 0.14345676, 0.3221199 ,\n       0.54626435, 0.05247523, 0.44302863, 0.17156485, 0.01036572,\n       0.11038927, 0.24487372, 0.1842391 , 0.09897886, 0.10906643,\n       0.15270433, 0.08704352, 0.20504801, 0.6898823 , 0.71309745,\n       0.13197719, 0.17253748, 0.13623197, 0.14979394, 0.778043  ,\n       0.9265778 , 0.12920925, 0.7722796 , 0.7456334 , 0.34568685,\n       0.6183766 , 0.71665514, 0.91456693, 0.4032462 , 0.11064816,\n       0.1754228 , 0.14575799, 0.4526957 , 0.04772155, 0.8247301 ,\n       0.79114354, 0.14662042, 0.11657609, 0.21419041, 0.4938222 ,\n       0.8131437 , 0.01085462, 0.14230569, 0.24000977, 0.64143956,\n       0.21609125, 0.81360656, 0.42353892, 0.6279257 , 0.81360006,\n       0.04413903, 0.33466363, 0.49639377, 0.9009948 , 0.17857762,\n       0.20937777, 0.11951587, 0.25856745, 0.11590686, 0.4577354 ,\n       0.05417406, 0.15685193, 0.22206935, 0.2678115 , 0.12104614,\n       0.61424804, 0.12852955, 0.20882972, 0.40227804, 0.07904069,\n       0.07243823, 0.09597398, 0.5582065 , 0.6837232 , 0.60769826,\n       0.17222726, 0.1842391 , 0.8024549 , 0.44428876, 0.17468162,\n       0.8861606 , 0.14960958, 0.18082184, 0.9142349 , 0.4921761 ,\n       0.08966002, 0.56817144, 0.65898967, 0.44368038, 0.14230569,\n       0.3727338 , 0.7264245 , 0.16053534, 0.11303405, 0.7565655 ,\n       0.28109613, 0.1517489 , 0.11278065, 0.1439453 , 0.20095034,\n       0.20650253, 0.06123041, 0.12383319, 0.21246769, 0.1766723 ,\n       0.21388449, 0.2142468 , 0.0308429 , 0.47555867, 0.16032799,\n       0.7079263 , 0.04633978, 0.3734499 , 0.35721204, 0.16195329,\n       0.49435878, 0.18272828, 0.10486217, 0.17374513, 0.42228472,\n       0.39870372, 0.5250781 , 0.09030818, 0.4131699 , 0.21253806,\n       0.19547969, 0.44999865, 0.728227  , 0.47762933, 0.31833214,\n       0.9146028 , 0.1345935 , 0.17348821, 0.19120577, 0.12964827,\n       0.21078065, 0.6569143 , 0.50583327, 0.36035904, 0.47653922,\n       0.16413644, 0.28400993, 0.4108329 , 0.6524874 , 0.11694703,\n       0.06840017, 0.05847865, 0.1639591 , 0.08108988, 0.3291084 ,\n       0.06276496, 0.06143029, 0.11089393, 0.4779028 , 0.06758752,\n       0.3197732 , 0.29717064, 0.20522632, 0.2142468 , 0.1010375 ,\n       0.14914675, 0.48118258, 0.4411424 , 0.0332576 , 0.0199015 ,\n       0.70674616, 0.69677985, 0.13255091, 0.10045985, 0.45536277,\n       0.15516426, 0.14175019, 0.22195587, 0.16308774, 0.60666806,\n       0.78885055, 0.13536312, 0.21640462, 0.21530503, 0.09061468,\n       0.6998756 , 0.7404194 , 0.3330702 , 0.35379082, 0.60221285,\n       0.12261211, 0.34642535, 0.46189946, 0.13308416, 0.31541875,\n       0.13742827, 0.31830427, 0.08950924, 0.72151   , 0.15270433,\n       0.55089754, 0.06629793, 0.05847865, 0.06123041, 0.20425314,\n       0.5092201 , 0.19500577, 0.12427119, 0.5115634 , 0.19113386,\n       0.7639504 , 0.58902067, 0.6222743 , 0.43097025, 0.43033963,\n       0.3344639 , 0.7130141 , 0.06994874, 0.51523745, 0.18045469,\n       0.5248896 , 0.741723  , 0.41388315, 0.16294467, 0.18035617,\n       0.08054987, 0.32550436, 0.6505414 , 0.14912109, 0.0578315 ,\n       0.18365735, 0.39524084, 0.18231682, 0.28181002, 0.08929481,\n       0.02445645, 0.35674173, 0.34964973, 0.2205117 , 0.33537987,\n       0.1572918 , 0.5688642 , 0.08966002, 0.4646079 , 0.7440325 ,\n       0.09676958, 0.47770542, 0.6633459 , 0.07460437, 0.5465445 ,\n       0.15418723, 0.07275796, 0.6129655 , 0.03755482, 0.26557776,\n       0.2018118 , 0.02333228, 0.48679522, 0.42642108, 0.04669081,\n       0.34204018, 0.11310561, 0.09958097, 0.4742327 , 0.5400734 ,\n       0.82548124, 0.2419194 , 0.07680956, 0.5936436 , 0.10695176,\n       0.24079107, 0.5242937 , 0.17270747, 0.18385196, 0.5119061 ,\n       0.34803972, 0.16111885, 0.33315384, 0.11809228, 0.04351088,\n       0.68542635, 0.12277773, 0.0363961 , 0.02955282, 0.41651782,\n       0.44230932, 0.21078065, 0.08966002, 0.32910335, 0.29267067,\n       0.17090024, 0.6837232 , 0.44453108, 0.4779028 , 0.6069343 ,\n       0.18231682, 0.18283966, 0.16836025, 0.4919567 , 0.16713104,\n       0.2373662 , 0.61831766, 0.17511734, 0.23231572, 0.6932845 ,\n       0.76342857, 0.06228201, 0.1659456 , 0.07040571, 0.16795455,\n       0.6158867 , 0.20937777, 0.04938251, 0.3699596 , 0.56913406,\n       0.0132331 , 0.15412053, 0.19220862, 0.13373774, 0.25858667,\n       0.31066763, 0.99330914, 0.68995935, 0.18768905, 0.43955773,\n       0.15702239, 0.513211  , 0.45785657, 0.21227589, 0.1924777 ,\n       0.88014174, 0.5899541 , 0.5024655 , 0.13840103, 0.08971279,\n       0.05178981, 0.04669081, 0.719202  , 0.05098139, 0.90143913,\n       0.35848302, 0.390976  , 0.1502114 , 0.12369088, 0.23224689,\n       0.09157979, 0.22835359, 0.81544286, 0.6109979 , 0.4304188 ,\n       0.11481299, 0.05025697, 0.17928492, 0.9133621 , 0.19392851,\n       0.08423363, 0.5486885 , 0.18986592, 0.13247266, 0.05618455,\n       0.5892708 , 0.18065098, 0.32107008, 0.42527238, 0.1552739 ,\n       0.8886726 , 0.5063024 , 0.23231572, 0.23231572, 0.17790642,\n       0.23006406, 0.9935821 , 0.6577088 , 0.915214  , 0.24748759,\n       0.09458306, 0.34027857, 0.44911474, 0.1910791 , 0.5946574 ,\n       0.11049688, 0.5000817 , 0.46763647, 0.09305078, 0.14427277,\n       0.5313637 , 0.46533936, 0.11002667, 0.29462406, 0.08108988,\n       0.70666987, 0.05223601, 0.18201286, 0.7365022 , 0.2166003 ,\n       0.613661  , 0.13523014, 0.09194693, 0.15082043, 0.03681663,\n       0.03950701, 0.07343066, 0.19188556, 0.4985795 , 0.8880858 ,\n       0.32298806, 0.61700165, 0.4407638 , 0.12335195, 0.12472787,\n       0.2229253 , 0.44271132, 0.45587888, 0.6336864 , 0.5220764 ,\n       0.12926097, 0.10214169, 0.18122569, 0.11814141, 0.1069053 ,\n       0.32852435, 0.13247266, 0.3447139 , 0.7205633 , 0.46716854,\n       0.11070453, 0.09377282, 0.06494014, 0.22697926, 0.10214169,\n       0.5805694 , 0.12272111, 0.1652372 , 0.10944285, 0.43191674,\n       0.09783074, 0.17228329, 0.4635981 , 0.04483794, 0.4293776 ,\n       0.6571637 , 0.12166953, 0.06872264, 0.16378355, 0.45733958,\n       0.5496966 , 0.4407888 , 0.4762547 , 0.14389299, 0.19908874,\n       0.6651073 , 0.16980499, 0.58171564, 0.17173737, 0.3111327 ,\n       0.46354675, 0.08033374, 0.21640462, 0.05067595, 0.08510515,\n       0.46162674, 0.42393696, 0.00478341, 0.48604724, 0.5735121 ,\n       0.18606564, 0.22881763, 0.8242084 , 0.14340876, 0.32905498,\n       0.08061751, 0.23634483, 0.19012634, 0.22063312, 0.10437534,\n       0.24809423, 0.5725067 , 0.4507574 , 0.12277773, 0.44191575,\n       0.10987508, 0.04177169, 0.38559225, 0.28544262, 0.19569911,\n       0.18231685, 0.61290276, 0.43219215, 0.08482553, 0.21460648,\n       0.15652534, 0.12335195, 0.25941545, 0.1881495 , 0.5481478 ,\n       0.49254596, 0.10484146], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Optimization","metadata":{}},{"cell_type":"code","source":"def get_new_model(predictors):\n    n_cols = predictors.shape[1]\n    model = Sequential()\n    model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n    model.add(Dense(2, activation='softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:45:59.636686Z","iopub.execute_input":"2021-08-07T07:45:59.637093Z","iopub.status.idle":"2021-08-07T07:45:59.642554Z","shell.execute_reply.started":"2021-08-07T07:45:59.637058Z","shell.execute_reply":"2021-08-07T07:45:59.641678Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"lr_list = [0.00001,0.01, 1]\n\nfor lr in lr_list:\n    opt = SGD(learning_rate=lr)\n    model = get_new_model(predictors)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    model.fit(predictors, target)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T07:53:43.424491Z","iopub.execute_input":"2021-08-07T07:53:43.424937Z","iopub.status.idle":"2021-08-07T07:53:44.640829Z","shell.execute_reply.started":"2021-08-07T07:53:43.424896Z","shell.execute_reply":"2021-08-07T07:53:44.639884Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"23/23 [==============================] - 0s 1ms/step - loss: 2.4083 - accuracy: 0.6705\n23/23 [==============================] - 0s 1ms/step - loss: 3.3113 - accuracy: 0.5941\n23/23 [==============================] - 0s 1ms/step - loss: 435.7632 - accuracy: 0.5766\n","output_type":"stream"}]},{"cell_type":"code","source":"model = get_new_model(predictors)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(predictors, target, validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:01:15.660081Z","iopub.execute_input":"2021-08-07T08:01:15.660720Z","iopub.status.idle":"2021-08-07T08:01:16.489320Z","shell.execute_reply.started":"2021-08-07T08:01:15.660679Z","shell.execute_reply":"2021-08-07T08:01:16.488305Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"16/16 [==============================] - 1s 24ms/step - loss: 7.9863 - accuracy: 0.5343 - val_loss: 7.4518 - val_accuracy: 0.2944\n","output_type":"stream"},{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7faec44bb3d0>"},"metadata":{}}]},{"cell_type":"code","source":"early_stop = EarlyStopping(patience=2)\nmodel = get_new_model(predictors)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(predictors, target, validation_batch_size=0.3, epochs=30, callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-08-07T08:06:55.511513Z","iopub.execute_input":"2021-08-07T08:06:55.511913Z","iopub.status.idle":"2021-08-07T08:06:56.991847Z","shell.execute_reply.started":"2021-08-07T08:06:55.511880Z","shell.execute_reply":"2021-08-07T08:06:56.990582Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Epoch 1/30\n23/23 [==============================] - 0s 1ms/step - loss: 3.8416 - accuracy: 0.3076\nEpoch 2/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.6036\nEpoch 3/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.6772\nEpoch 4/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.6124 - accuracy: 0.6847\nEpoch 5/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.6176 - accuracy: 0.6753\nEpoch 6/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.6014 - accuracy: 0.6997\nEpoch 7/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7208\nEpoch 8/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7260\nEpoch 9/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.7022\nEpoch 10/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.6087 - accuracy: 0.6669\nEpoch 11/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7265\nEpoch 12/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7057\nEpoch 13/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.7209\nEpoch 14/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.7353\nEpoch 15/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.7117\nEpoch 16/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5317 - accuracy: 0.7454\nEpoch 17/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5451 - accuracy: 0.7231\nEpoch 18/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7069\nEpoch 19/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7463\nEpoch 20/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7195\nEpoch 21/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7368\nEpoch 22/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7158\nEpoch 23/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.7250\nEpoch 24/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7289\nEpoch 25/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5107 - accuracy: 0.7506\nEpoch 26/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7698\nEpoch 27/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7656\nEpoch 28/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7992\nEpoch 29/30\n23/23 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7605\nEpoch 30/30\n23/23 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7626\n","output_type":"stream"},{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fae9c41e7d0>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}